{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b18400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "parent_directory = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc4a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('smart-reply.xlsx')\n",
    "df.columns = ['emails','responses']\n",
    "df.head()\n",
    "input_texts = list(df['emails'])\n",
    "target_texts = list(df['responses'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93c318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration \n",
    "batch_size = 7# Batch size for training.\n",
    "epochs = 10  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 14  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318497dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "target_texts = [\"\\t\"+i+\"\\n\" for i in target_texts]\n",
    "for input_text in input_texts:\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "for target_text in target_texts:\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "        \n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855f6bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 19\n",
      "Number of unique input tokens: 66\n",
      "Number of unique output tokens: 70\n",
      "Max sequence length for inputs: 273\n",
      "Max sequence length for outputs: 304\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d0c9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0533d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce19adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c625a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 5s 771ms/step - loss: 3.8720 - accuracy: 0.3877 - val_loss: 2.9734 - val_accuracy: 0.7130\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 518ms/step - loss: 2.3926 - accuracy: 0.6980 - val_loss: 2.0897 - val_accuracy: 0.7113\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 1.9588 - accuracy: 0.6980 - val_loss: 1.9079 - val_accuracy: 0.7072\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 443ms/step - loss: 1.8558 - accuracy: 0.6882 - val_loss: 1.7642 - val_accuracy: 0.7072\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 458ms/step - loss: 1.7479 - accuracy: 0.6923 - val_loss: 1.7683 - val_accuracy: 0.7064\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 448ms/step - loss: 1.7285 - accuracy: 0.6945 - val_loss: 1.6148 - val_accuracy: 0.7122\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 453ms/step - loss: 1.6486 - accuracy: 0.6996 - val_loss: 1.6078 - val_accuracy: 0.7138\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 447ms/step - loss: 1.6341 - accuracy: 0.7011 - val_loss: 1.7908 - val_accuracy: 0.7146\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 456ms/step - loss: 1.6732 - accuracy: 0.7018 - val_loss: 1.5542 - val_accuracy: 0.7155\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 458ms/step - loss: 1.5916 - accuracy: 0.7029 - val_loss: 1.6152 - val_accuracy: 0.7122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 21:18:44.891330: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f467433aca0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f46743589a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b1a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa48458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Congratulations on the offer, your contract is attached\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: Congratulations on the offer, your contract is attached\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: Let's shoot for Tuesday at 11:45.\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: Hi . I have not been added to email group.  please do the needful. Thank you\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: Welcome! Your application to Woculus has been approved. We are proud to have you as one of our editors. The entire Woculus team looks forward to a very professional working relationship with you, and we ready to support you in any way possible to serve our audience better.\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: Hey Will! Remeber us dicussing deals showing up in Real-Time Position manager that are the EPMI-West-Bank. Can you remove these from this view? thanks, Diana \n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: I have release a new version of Real Time to Estate Stage. In the bottom left hand corner you can now select the portfolios which you want to see. Please take a look at it and let me know how it goes. Regards, Will\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: Can you tell me what day was the last to be rolled in Auto Scheduler? I'm trying to go back into December to balance Enpower for Settlement purposes. Thank you, Diana\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: Thanks Diana. Your enhancements completely make sense. Please let me know, after you talk to John, if you want the change implemented. Thanks\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence: I will forward you the appropriate operational people's contact names and numbers next week. Brian - can you give me the list of contacts that you would like to submit.\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence:  Is there anything you need me to do? If everything is in place, I will contact Gerry Cupp at Shasta letting him know. Or, if he needs to do something, I will get that started. Thanks\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n",
      "-\n",
      "Input sentence:  I just checked again, and there is no fax for you from them. You may want to verify with them that they can use fax number 7996\n",
      "Decoded sentence:                                                                                                                                                                                                                                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(12):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d6bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bdc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25f6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e79b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
