{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb463da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import PorterStemmer  # stemming \n",
    "from nltk.corpus import stopwords    # removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b915c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file \n",
    "text_file='''\n",
    "I have three visions for India.\n",
    "In 3000 years of our history, people from allover the world have come and invaded us, \n",
    "captured our lands, conquered our minds. From Alexander onwards. The Greeks, the Portuguese, \n",
    "the British, the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "We have not grabbed their land, their culture, their history tried to enforce our way of life on them. Why? \n",
    "Because we respect the freedom of others.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d416b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing words \n",
    "words = nltk.word_tokenize(text_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed7493ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', 'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', 'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', 'die', 'das', 'dass', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', 'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', 'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', 'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', 'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', 'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', 'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', 'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', 'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', 'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', 'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', 'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', 'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', 'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', 'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', 'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', 'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', 'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', 'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', 'zwischen']\n"
     ]
    }
   ],
   "source": [
    "# getting the stop  words of english language \n",
    "german_stopwords = stopwords.words('german') \n",
    "print(german_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98581c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming  \n",
    "# tokenizing sentences               \n",
    "sentences = nltk.sent_tokenize(text_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8705677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer() \n",
    "english_stopwords = stopwords.words('english') \n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word)   for word in words if word not in set(english_stopwords)] \n",
    "    sentences[i] = ' '.join(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e74d67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i three vision india .', 'in 3000 year histori , peopl allov world come invad us , captur land , conquer mind .']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0:2]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
